{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danadria/Skills-Lab-Introduction-to-Transformers-BERT-and-Explainable-NLP/blob/main/notebooks/llm_data_collection_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHhOlhjzjH0H"
      },
      "source": [
        "# Using Large Language Models for Data Collection in Social Sciences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2e1RcGZrj4e5",
        "outputId": "8b300c12-325b-42cc-e337-c97f80b8c627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install -qU langchain[openai] tqdm pydantic krippendorff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1B9Ok90OkqZC"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "import krippendorff"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TespdOjoM5v0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE3OlfYOlb0G"
      },
      "source": [
        "## Gabrielle Martins van Jaarsveld's SoDa fellowship dataset\n",
        "\n",
        "Feel free to use your own data. By default, we will use a toy dataset from Gabrielle Martins van Jaarsveld's SoDa fellowship project on annotating markers of self-regulated learning from student conversation data.\n",
        "\n",
        "This dataset contains the following columns:\n",
        "\n",
        "- `id`: The id of the row/conversation/student.\n",
        "\n",
        "- `conversation`: The text of the conversations based on which specificity scores are derived (by humans or LLMs).\n",
        "\n",
        "- `score_specificity_llm`: The specificity score of a conversation based on carefully prompted response from LLMs. It varies between 0, 1 and 2.\n",
        "\n",
        "- `score_specificity_human`: The specificity score of a conversation based on human expert annotators. It is treated as gold standard (i.e., free from measurement error). It varies between 0, 1 and 2.\n",
        "\n",
        "- `performance`: The academic performance of a student, varying from 1 to 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-LyJLcM4RzT"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w6iO_UFkm2aQ"
      },
      "outputs": [],
      "source": [
        "# url where you can download our example data\n",
        "data_url = \"https://sodascience.github.io/workshop_llm_data_collection/data/srl_data_example.csv\"\n",
        "\n",
        "# Read CSV into dataframe\n",
        "df = pd.read_csv(data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0lSfXdFEb7z"
      },
      "source": [
        "Display the first 10 rows of the dataset.\n",
        "\n",
        "Note that only the first 10 rows contain the text of the conversations. We will use these texts for the prompting experiments to come."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kvZ5ZgGIEepO",
        "outputId": "ec647e7a-23a0-426f-af13-e8cae8feb696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                       conversation  \\\n",
              "0   request_1  PROMPT: Set an academic goal for the upcoming ...   \n",
              "1   request_2  PROMPT: Set an academic goal for the upcoming ...   \n",
              "2   request_3  PROMPT: Set an academic goal for the upcoming ...   \n",
              "3   request_4  PROMPT: Set an academic goal for the upcoming ...   \n",
              "4   request_5  PROMPT: Set an academic goal for the upcoming ...   \n",
              "5   request_6  PROMPT: Set an academic goal for the upcoming ...   \n",
              "6   request_7  PROMPT: Set an academic goal for the upcoming ...   \n",
              "7   request_8  PROMPT: Set an academic goal for the upcoming ...   \n",
              "8   request_9  PROMPT: Set an academic goal for the upcoming ...   \n",
              "9  request_10  PROMPT: Set an academic goal for the upcoming ...   \n",
              "\n",
              "   score_specificity_llm  score_specificity_human  performance  \n",
              "0                      1                      1.0          3.5  \n",
              "1                      2                      2.0          6.8  \n",
              "2                      0                      0.0          6.7  \n",
              "3                      1                      1.0          7.3  \n",
              "4                      1                      1.0          5.8  \n",
              "5                      1                      1.0          6.4  \n",
              "6                      2                      1.0          5.9  \n",
              "7                      0                      0.0          7.6  \n",
              "8                      1                      1.0          7.6  \n",
              "9                      2                      2.0          7.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e115222-1446-4cd6-a41b-66f304a882c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation</th>\n",
              "      <th>score_specificity_llm</th>\n",
              "      <th>score_specificity_human</th>\n",
              "      <th>performance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>request_1</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>request_2</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>request_3</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>request_4</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>request_5</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>request_6</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>request_7</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>request_8</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>request_9</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>request_10</td>\n",
              "      <td>PROMPT: Set an academic goal for the upcoming ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e115222-1446-4cd6-a41b-66f304a882c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e115222-1446-4cd6-a41b-66f304a882c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e115222-1446-4cd6-a41b-66f304a882c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0aca818-725f-4212-8c38-8f3f89a97af5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0aca818-725f-4212-8c38-8f3f89a97af5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0aca818-725f-4212-8c38-8f3f89a97af5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 80,\n        \"samples\": [\n          \"request_31\",\n          \"request_1\",\n          \"request_23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conversation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"PROMPT: Set an academic goal for the upcoming week.\\nANSWER: I would like to keep on track with the readings I have to do\\nPROMPT: Add details to make your goal more specific.\\nANSWER: Every week we have two tutorials, which are smaller groups, where we have a debate about the readings we have done before. Each week for both of them we have more than 100 pages to read and we need to arrive prepared at the tutorial. So I would like to manage better my time in order to arrive prepared at every tutorial with all the readings well done\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: I can decide how many pages I have to study each day\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: I think is good because it will help me in manage my time better, but also i will have more time for myself, for working, hanging out with friends. I also think is fundamental to learn how to manage many things all together at the same time now at university, because later on it will be even worse\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: At first I will count all the pages i have to do, so that i know exactly how much work is, after I will take the calendar and i will divide the work for every day, writing precisely how many pages i should do each day. After that, every day i will try to stick to the plan as much as possible and maybe to motivate myself, I will decide a reward that I can have just if i manage to do everything that was written in the plan of the day\",\n          \"PROMPT: Set an academic goal for the upcoming week.\\nANSWER: I would like write notes on theme 1 from my mathematics course. \\nPROMPT: Add details to make your goal more specific.\\nANSWER: I will take notes on Chapter 1 from the Basic Algebra book and the two articles that belonged to theme 1\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: I will split it into three parts. First the book chapter, then the first article and lastly the second article. When there is well written notes that sums up the important parts from the reading i will have achieved my goal.\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: By achieving this goal I will remember and understand the material better, which will make it easier so study for the upcoming exam. I will not feel as overwhelmed as for earlier exam because I have made good notes that I can go through instead of going through all the materials.\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: 1. Go to a nice cafe where I can study uninterrupted \\n2. Read through the highlighted parts of the book chapter and simultaneously write down notes for it. \\n3. Read through the highlighted parts of the first article and simultaneously write down notes for it. \\n4. Read through the highlighted parts of the second article and simultaneously write down notes for it. \\n5. Red over all the notes and check that it makes sense and give a good summary of the important parts of the material.\",\n          \"PROMPT: Set an academic goal for the upcoming week.\\nANSWER: Doing the reading and taking notes before class\\nPROMPT: Add details to make your goal more specific.\\nANSWER: I would like to read the given pages before my classes, which are on Mondays, Wednesdays, and Thursdays. Each class requires us to have read certain pages and articles, and then discuss in class. However, I have troubles which time management, which is why I never get the reading done in time and then cram before exams\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: I will measure my progress by examinig the notes I have prepared for every class, and we can measure if Ive achieved it by maybe asking some questions about the literature?\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: Because cramming all the material before exams has had a severe impact on my grades, and Im trying to fix my average with the upcoming exams, so I need to ensure that my method will give me best results\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: Start every preperation with a video explaining the concept briefly, then read the literature while taking notes by hand. Have all this done latest a day before the lesson.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_specificity_llm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_specificity_human\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6914918072835209,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"performance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.282136449007622,\n        \"min\": 1.2,\n        \"max\": 8.7,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          7.2,\n          8.7,\n          8.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhiH0VRqljn2"
      },
      "source": [
        "## Using langchain to call OpenAI's API\n",
        "\n",
        "We will be using the Python package `langchain` to perform our prompting experiments. One great advantage of using `langchain` is that it takes away the trouble of having to learn different LLM APIs. Instead, it allows you to call different LLM APIs (both commercial and open-source) effortlessly (relatively speaking) with very simple modifications of your `langchain` code!\n",
        "\n",
        "We will be calling OpenAI's LLM in this notebook. Feel free to experiment with other APIs and models! To do so, check out https://python.langchain.com/docs/tutorials/chatbot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUBe3-xbMq-e"
      },
      "source": [
        "Initialise an LLM model. You need to enter your OpenAI API key for this when being prompted. Don't have one? Ask the workshop instructors!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D01Wli7ilI83",
        "outputId": "6ff894b6-ee3d-498c-c2c2-7312c82a7560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "model = init_chat_model(\"gpt-4o-mini\",\n",
        "                        model_provider=\"openai\",\n",
        "                        temperature=0,\n",
        "                        max_tokens=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tqa79dHqSrQH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5bCH0msmBNC"
      },
      "source": [
        "## Working with a single prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7pQ9bJjeYpL"
      },
      "source": [
        "Let's start with the system prompt (i.e., high-level instruction to the model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6DHz1SuRp964"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "\"You are an expert in educational assessment and goal evaluation, with specialized expertise in applying deductive coding schemes to score the quality and content of student goals.\n",
        "You have a deep understanding of scoring rubrics and are highly skilled at analysing goals for specific characteristics according to well-defined criteria.\n",
        "\n",
        "##TASK##\n",
        "A university student was given a series of prompts, guiding them through the\n",
        "process of setting and elaborating on an academic goal for the coming week. You\n",
        "will be provided with the entire conversation including the prompts, and the\n",
        "student answers. Your objective is to assess the specificity of of the student’s\n",
        "goal on a scale of 0 to 2 based on the entire conversation.\n",
        "\n",
        "##EVALUATION CRITERIA##\n",
        "Assign the scores based on the following criteria:\n",
        "SPECIFICITY: ASSESS the extent to which the goal is specific rather than general.\n",
        "DETERMINE if goal is measurable, assessable, documentable, or observable. Is the outcome measurable, and is it possible to track progress while working on the goal?\n",
        "PERSONAL IMPORTANCE: DETERMINE if there is an explicit reason for the goal which outlines why this goal is important to achieve on the basis of previous experience or in the context of future goals.\n",
        "MULTI-SOURCE PLANNING: EXAMINE whether there are specific activities mentioned, and whether these activities directly relate to the goal. Is there a schedule included mentioning days or times of day for working on these activities and accomplishing the goal?\n",
        "\n",
        "##SCORING INSTRUCTIONS##\n",
        "For each category, ASSIGN a score of 0 (lowest), 1, or 2 (highest).\n",
        "IDENTIFY the key elements that distinguish a low score (0) from a high score (2)\n",
        "in each category and provides reasoning for each criteria.\n",
        "Base on all the scores received, produce an average, overall score that is most representative of the goal quality of the student.\n",
        "\n",
        "##EDGE CASE HANDLING##\n",
        "If a goal is ambiguous or unclear, SCORE it on the lower end.\n",
        "If a goal appears to partially meet the criteria for two different scores, SELECT\n",
        "the score that best reflects the majority of the goals characteristics for that category.\n",
        "\n",
        "##WHAT NOT TO DO##\n",
        "Never apply personal opinion or assumptions outside the rubric criteria.\n",
        "never give a score without a detailed explanation, even if the scoring seems obvious.\n",
        "never modify or assume student intent score the goal exactly as written.\n",
        "never ignore the rubric or provided examples when scoring\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HivI2QseewJ"
      },
      "source": [
        "Use the prompt template module from langchain to create a prompt request with both **system** and **user** prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "bEQtu3AcWlVn"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", \"{conversation}\")\n",
        "])\n",
        "\n",
        "# Create a prompt request with the system prompt and the user prompt based on\n",
        "# the first conversation from the dataset\n",
        "prompt_request = prompt_template.invoke({\"conversation\": df.iloc[0,1]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_CixxrPel8s"
      },
      "source": [
        "Check the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "jam82IDfLz2Y",
        "outputId": "85cde887-d115-4f56-8508-aa5e2f46a3a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='\\n\"You are an expert in educational assessment and goal evaluation, with specialized expertise in applying deductive coding schemes to score the quality and content of student goals. \\nYou have a deep understanding of scoring rubrics and are highly skilled at analysing goals for specific characteristics according to well-defined criteria.\\n\\n##TASK##\\nA university student was given a series of prompts, guiding them through the\\nprocess of setting and elaborating on an academic goal for the coming week. You\\nwill be provided with the entire conversation including the prompts, and the\\nstudent answers. Your objective is to assess the specificity of of the student’s\\ngoal on a scale of 0 to 2 based on the entire conversation.\\n\\n##EVALUATION CRITERIA##\\nAssign the scores based on the following criteria:\\nSPECIFICITY: ASSESS the extent to which the goal is specific rather than general. \\nDETERMINE if goal is measurable, assessable, documentable, or observable. Is the outcome measurable, and is it possible to track progress while working on the goal?\\nPERSONAL IMPORTANCE: DETERMINE if there is an explicit reason for the goal which outlines why this goal is important to achieve on the basis of previous experience or in the context of future goals.\\nMULTI-SOURCE PLANNING: EXAMINE whether there are specific activities mentioned, and whether these activities directly relate to the goal. Is there a schedule included mentioning days or times of day for working on these activities and accomplishing the goal?\\n\\n##SCORING INSTRUCTIONS##\\nFor each category, ASSIGN a score of 0 (lowest), 1, or 2 (highest).\\nIDENTIFY the key elements that distinguish a low score (0) from a high score (2) \\nin each category and provides reasoning for each criteria.\\nBase on all the scores received, produce an average, overall score that is most representative of the goal quality of the student.\\n\\n##EDGE CASE HANDLING##\\nIf a goal is ambiguous or unclear, SCORE it on the lower end.\\nIf a goal appears to partially meet the criteria for two different scores, SELECT \\nthe score that best reflects the majority of the goals characteristics for that category.\\n\\n##WHAT NOT TO DO##\\nNever apply personal opinion or assumptions outside the rubric criteria.\\nnever give a score without a detailed explanation, even if the scoring seems obvious.\\nnever modify or assume student intent score the goal exactly as written.\\nnever ignore the rubric or provided examples when scoring\\n', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='PROMPT: Set an academic goal for the upcoming week.\\nANSWER: I would like to catch up on my geography reading\\nPROMPT: Add details to make your goal more specific.\\nANSWER: I need to either read the book from last week and this week, or read my friends notes on the reading to take notes of my own so I dont fall behind.\\nPROMPT: How will you measure progress on and acheivement of your goal?\\nANSWER: by the number of pages I write per day\\nPROMPT: Why is this goal important to you in the context of your prior experiences and future goals?\\nANSWER: It is important to achieve because if I dont, I will fall behind and most likely wont be ready for the exam.\\nPROMPT: Create a step-by-step plan for achieving this goal in the coming week.\\nANSWER: 1. evaluate how much there is to do \\n2. get help from my friends \\n3. takes notes day by day', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "prompt_request.to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWHolr5NetK-"
      },
      "source": [
        "Prompt the model and inspect the response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Chb3505UWnfk",
        "outputId": "fa47822d-a8a5-4914-9ba4-dfa5d8ec2850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Evaluation of the Student's Goal\n",
            "\n",
            "**1. Specificity:**\n",
            "- **Score: 1**\n",
            "- **Reasoning:** The goal is somewhat specific as it mentions catching up on geography reading and provides options (reading the book or friends' notes). However, it lacks precise details about which specific chapters or pages to read, and it does not specify a clear outcome or target for completion. A score of 2 would require a more detailed plan with specific chapters or a clear target for completion.\n",
            "\n",
            "**2. Measurable:**\n",
            "- **Score: 1**\n",
            "- **Reasoning:** The student mentions measuring progress by the number of pages written per day, which is a measurable aspect. However, it does not specify how many pages are to be read or written in total, nor does it outline a clear method for tracking this progress over the week. A score of 2 would require a more comprehensive measurement plan.\n",
            "\n",
            "**3. Personal Importance:**\n",
            "- **Score: 2**\n",
            "- **Reasoning:** The student clearly articulates the importance of the goal by stating that falling behind could affect their readiness for the exam. This provides a strong personal motivation for achieving the goal, which aligns well with the criteria for a high score.\n",
            "\n",
            "**4. Multi-Source Planning:**\n",
            "- **Score: 1**\n",
            "- **Reasoning:** The student outlines a basic step-by-step plan that includes evaluating the workload, seeking help from friends, and taking notes. However, it lacks specific days or times for these activities, which would enhance the planning aspect. A score of 2 would require a more detailed schedule with specific times allocated for each activity.\n",
            "\n",
            "### Overall Score Calculation\n",
            "- Specificity: 1\n",
            "- Measurable: 1\n",
            "- Personal Importance: 2\n",
            "- Multi-Source Planning: 1\n",
            "\n",
            "**Average Score: (1 + 1 + 2 + 1) / 4 = 1.25**\n",
            "\n",
            "### Final Overall Score\n",
            "**Final Score: 1** \n",
            "\n",
            "This score reflects that while the goal has some specific elements and personal importance, it lacks sufficient detail and clarity in terms of specificity, measurability, and planning to achieve a higher score.\n"
          ]
        }
      ],
      "source": [
        "response = model.invoke(prompt_request)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MfKrGf3e4MZ"
      },
      "source": [
        "Voila! You have your first successful prompting interaction with the API of a large language model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teHsF27YceX_"
      },
      "source": [
        "## Working with multiple prompts\n",
        "Next, we are going beyond a single prompt. Instead, we will work with **multiple prompts** at the same time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hhigdP9THoO"
      },
      "source": [
        "Define a list of request IDs and another list of conversations (necessary for forming the user prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "UAfnxKlQf4eQ"
      },
      "outputs": [],
      "source": [
        "ids = df.id[:10].tolist()\n",
        "conversations = df.conversation[:10].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Y0b78F6Chy_s",
        "outputId": "3f479ec0-115e-4e28-bdc5-1b8ae1b7b988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Requests: 100%|██████████| 10/10 [01:33<00:00,  9.39s/it]\n"
          ]
        }
      ],
      "source": [
        "responses = {}\n",
        "for id, conversation in tqdm(zip(ids, conversations),\n",
        "                             total=len(ids),\n",
        "                             desc=\"Processing Requests\"):\n",
        "    prompt_request = prompt_template.invoke({\"conversation\": conversation})\n",
        "    response = model.invoke(prompt_request)\n",
        "    responses[id] = response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9lYcc12LFht"
      },
      "source": [
        "Inspect the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "f3KOt37Hi-UX",
        "outputId": "e567578f-2576-473b-9ed2-4ed625fcc8a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Evaluation of the Student's Goal\n",
            "\n",
            "**1. Specificity:**\n",
            "- **Score: 1**\n",
            "- **Reasoning:** The goal \"to not procrastinate\" is quite general and lacks specificity. The student attempts to add details by mentioning reducing phone time and not leaving reading until the last minute, which provides some context. However, the goal remains vague as it does not specify what \"not procrastinating\" entails in measurable terms. The details provided do not clearly define what success looks like or how it can be tracked.\n",
            "\n",
            "**2. Measurable Outcome:**\n",
            "- **Score: 1**\n",
            "- **Reasoning:** The student mentions measuring progress by \"finishing work at a certain time of the day.\" While this indicates a measurable aspect, it lacks clarity on what that specific time is or how it will be tracked. The goal does not provide a clear metric for success, making it difficult to assess progress effectively.\n",
            "\n",
            "**3. Personal Importance:**\n",
            "- **Score: 1**\n",
            "- **Reasoning:** The student states that the goal is important \"to help me strategically work, and study smart.\" While this indicates some personal relevance, it does not elaborate on how this goal connects to past experiences or future aspirations. The reasoning is somewhat vague and does not provide a strong personal motivation for achieving the goal.\n",
            "\n",
            "**4. Multi-Source Planning:**\n",
            "- **Score: 1**\n",
            "- **Reasoning:** The student outlines a step-by-step plan that includes reducing phone time, organizing workload, and spreading workload evenly across the week. However, the plan lacks specific details such as when these activities will take place (e.g., specific days or times). While there are activities mentioned, they do not directly relate to a clear, measurable goal, and the absence of a schedule limits the effectiveness of the planning.\n",
            "\n",
            "### Overall Score Calculation\n",
            "- Specificity: 1\n",
            "- Measurable Outcome: 1\n",
            "- Personal Importance: 1\n",
            "- Multi-Source Planning: 1\n",
            "\n",
            "**Average Score: (1 + 1 + 1 + 1) / 4 = 1**\n",
            "\n",
            "### Final Assessment\n",
            "The overall score for the student's goal is **1**. The goal demonstrates some effort towards specificity and planning but ultimately lacks clarity, measurable outcomes, and strong personal relevance. Improvements could be made by defining the goal more clearly, establishing specific metrics for success, and providing a more detailed rationale for its importance.\n"
          ]
        }
      ],
      "source": [
        "print(responses['request_3'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59gpSzXadJej"
      },
      "source": [
        "## Using structured output with a single prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuEez0lGTf78"
      },
      "source": [
        "To force the LLM to produce outputs in formats specified by you, you need to use the `BaseModel` and `Field` classes from the `pydantic` package.\n",
        "\n",
        "Below, we define our desired output format as:\n",
        "- \"specificity_score\": an integer (either 0, 1 or 2) reflecting the specificity of a conversation.\n",
        "- \"reasoning\": a string that provides the model's reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hbluX4wfdPqx"
      },
      "outputs": [],
      "source": [
        "class SpecificityFormat(BaseModel):\n",
        "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
        "    specificity_score: int = Field(description=\"The specificity score of the entire conversation on a scale of 0, 1 and 2.\")\n",
        "    reasoning: str = Field(description=\"Your reasoning process.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHATrS3zUpML"
      },
      "source": [
        "Try with a single prompt request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "8qFPaYJCmRUs"
      },
      "outputs": [],
      "source": [
        "# Bind responseformatter schema to the model\n",
        "model_structured = model.with_structured_output(SpecificityFormat)\n",
        "\n",
        "# try to run a request throught this new model\n",
        "prompt_request = prompt_template.invoke({\"conversation\": df.iloc[0,1]})\n",
        "structured_response = model_structured.invoke(prompt_request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "v1wxfPM6k7PJ",
        "outputId": "d81585d4-e4bc-4760-b996-77d48539dc8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'specificity_score': 1,\n",
              " 'reasoning': \"1. SPECIFICITY: The goal is somewhat specific as it mentions catching up on geography reading, but it lacks precise details about the exact pages or chapters to be read. The mention of reading friends' notes adds some clarity, but it is still vague regarding the exact content. Score: 1.\\n\\n2. MEASURABILITY: The goal includes a measurable aspect by stating progress will be tracked by the number of pages written per day. However, it does not specify how many pages are expected to be read or written, which limits the ability to fully assess progress. Score: 1.\\n\\n3. PERSONAL IMPORTANCE: The student provides a reason for the goal, indicating that falling behind could affect their exam readiness. This shows some personal importance, but it could be more detailed regarding how this goal aligns with their overall academic aspirations. Score: 1.\\n\\n4. MULTI-SOURCE PLANNING: The step-by-step plan includes evaluating the workload, seeking help from friends, and taking notes daily. However, it lacks specific days or times for these activities, making it less actionable. Score: 1.\\n\\nOverall, the goal demonstrates some specificity and planning but lacks detailed measurable outcomes and a clear timeline, leading to an average score of 1.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "dict(structured_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWmyBbl0LnOR"
      },
      "source": [
        "## Using structured output with multiple prompts\n",
        "\n",
        "Being able to work with multiple prompts at the same time and obtain structured output will save you a substantial amount of time in research projects!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "X6zuVgkJrqVV",
        "outputId": "f97fa3bc-4718-4288-a554-158c5413af1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Messages: 100%|██████████| 10/10 [00:52<00:00,  5.27s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "structured_responses = {}\n",
        "for id, conversation in tqdm(zip(ids, conversations), total=len(ids), desc=\"Processing Messages\"):\n",
        "    prompt_request = prompt_template.invoke({\"conversation\": conversation})\n",
        "    structured_response = model_structured.invoke(prompt_request)\n",
        "    # Below we save only the specificity scores\n",
        "    structured_responses[id] = dict(structured_response)[\"specificity_score\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMyf6gljIsYV"
      },
      "source": [
        "Display all the structured responses (only the specificity scores)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5_NYNFRGsO2d",
        "outputId": "05b2be92-5217-4815-bf96-0f4461012e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'request_1': 1,\n",
              " 'request_2': 2,\n",
              " 'request_3': 1,\n",
              " 'request_4': 2,\n",
              " 'request_5': 1,\n",
              " 'request_6': 2,\n",
              " 'request_7': 2,\n",
              " 'request_8': 1,\n",
              " 'request_9': 1,\n",
              " 'request_10': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "structured_responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3eLGxm5dW1f"
      },
      "source": [
        "## Check annotation quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hE7knNFJD54"
      },
      "source": [
        "Implement a handy function to calculate Krippendorff's Alpha (i.e., agreement) between two lists of specificity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "q9zndWAmJBcQ"
      },
      "outputs": [],
      "source": [
        "def compute_krippendorff_alpha(x: list[int], y: list[int]):\n",
        "  # Format data into a reliability matrix (rows=raters, cols=items)\n",
        "  data_krippendorff = np.array([x, y])\n",
        "  # Compute Krippendorff’s Alpha (interval metric)\n",
        "  kripp_alpha = krippendorff.alpha(reliability_data=data_krippendorff, level_of_measurement='interval')\n",
        "  return kripp_alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRNqIXIqJN6-"
      },
      "source": [
        "Let's check the agreement between the specificity scores we got from the LLM above and the human expert-coded specificity scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "apooHATcs1wp",
        "outputId": "1fa3a109-3f1d-410e-d44b-14c5988fde65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Krippendorff's Alpha: 0.3870967741935484\n"
          ]
        }
      ],
      "source": [
        "score_specificity_human = df.score_specificity_human[:10].tolist()\n",
        "structured_response_values = list(structured_responses.values())\n",
        "print(\"Krippendorff's Alpha:\", compute_krippendorff_alpha(structured_response_values, score_specificity_human))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4kQllO3JhML"
      },
      "source": [
        "Not a great agreement score!\n",
        "\n",
        "How about the agreement between the LLM specificity scores that already came with the dataset (i.e., column `score_specificity_llm`) and the human expert-coded scores?\n",
        "\n",
        "Note that `score_specificity_llm` is based on prompts that were carefully engineered by Gabrielle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Z97P-AtdnR4K",
        "outputId": "d86e149e-5996-4648-fa7a-c0b83fdd9dd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Krippendorff's Alpha: 0.8938547486033519\n"
          ]
        }
      ],
      "source": [
        "score_specificity_llm = df.score_specificity_llm[:10].tolist()\n",
        "print(\"Krippendorff's Alpha:\", compute_krippendorff_alpha(score_specificity_llm, score_specificity_human))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMRpL4zIKZOr"
      },
      "source": [
        "Wow! Much better result!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I28nCUtjkFt"
      },
      "source": [
        "## Exercise: Try different prompting techniques to get better results!\n",
        "\n",
        "For example:\n",
        "\n",
        "1. Improve clarity & specificity\n",
        "2. Role-based prompting\n",
        "3. Step-by-step reasoning (Chain-of-Thought Prompting)\n",
        "4. Few-shot prompting\n",
        "5. Output structuring\n",
        "6. Self-consistency prompting\n",
        "\n",
        "Use the previous `compute_krippendorff_alpha` function to check the LLM's annotation quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTrRxc-LuktS"
      },
      "outputs": [],
      "source": [
        "# Let's write some code!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}